{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dc79766",
   "metadata": {},
   "source": [
    "# Library\n",
    "[Naive vs Advance  Rags Blog](https://medium.com/@myscale/naive-rag-vs-advanced-rag-17b38cda44c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d30e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a4d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.llms.llamafile import Llamafile\n",
    "from langchain.prompts import PromptTemplate,ChatPromptTemplate\n",
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2f5d63",
   "metadata": {},
   "source": [
    "# Load Emberding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ece5753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10580\\3511400781.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model=HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2',\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "embedding_model=HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2',\n",
    "                                      model_kwargs = {'device': device})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6cf33",
   "metadata": {},
   "source": [
    "# Load Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3957dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.load_local(folder_path=\"vector_db/faiss_index_hybride_all_books\",\n",
    "                               embeddings=embedding_model,\n",
    "                               allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddabcde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create a retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d796c09a",
   "metadata": {},
   "source": [
    "# Load LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81845f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Llamafile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "706b0009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\". Here's one:\\n\\nWhat do you call a fake noodle?\\n\\nAn impasta!\\n\\nHow was that? Do you want to hear another one?<|eot_id|>\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "451e8e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " about a tree\n",
      "Here's one:\n",
      "Why did the tree go to the party?\n",
      "\n",
      "(Wait for it...)\n",
      "\n",
      "Because it wanted to branch out and meet new people!\n",
      "\n",
      "Hope that made you leaf through your laughter! (Sorry, I couldn't resist!)<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me a joke\"\n",
    "\n",
    "for chunks in llm.stream(query):\n",
    "    print(chunks, end=\"\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f837b",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c633f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiation using from_template (recommended)\n",
    "# prompt = PromptTemplate.from_template(\"Say {foo}\")\n",
    "# prompt.format(foo=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa597097",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a Tolkien scholar assistant.\"),\n",
    "    (\"system\", \"Use the provided LOTR context to answer the question with citations.\"),\n",
    "    (\"human\", \"Context: {context}\\n\\nQuestion: {query}\\nAnswer:\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ffeff6",
   "metadata": {},
   "source": [
    "# Complitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b50d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create QA chain\n",
    "# qa_chain = RetrievalQA.from_chain_type(\n",
    "#     llm=llm,\n",
    "#     chain_type=\"stuff\",\n",
    "#     retriever=retriever,\n",
    "#     return_source_documents=True,\n",
    "#     chain_type_kwargs={\n",
    "#         'prompt': prompt\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05e6243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
    "qa_chain = create_retrieval_chain(retriever, combine_docs_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1c81df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'what is Narsil?'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e9c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = qa_chain.invoke({\"input\": query, \"query\": query})\n",
    "\n",
    "print(\"RESULT: \", response[\"answer\"])\n",
    "print(\"SOURCE DOCUMENTS: \", response[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c285d23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Narsil is a sword, specifically the sword of Elendil that was broken and had its light extinguished, but it has not yet been forged again. (From various citations: 231, 41, 160, 41) \n",
      "Narsil's name is composed of two basic stems without variation or adjuncts: √NAR 'fire' & √THIL 'white light'. This symbolises the shards of the sword that was broken, and its name is thus associated with fire and light. (From context: Ernil i Pheriannath III 41 cf. 231) \n",
      "\n",
      "Note: As a Tolkien scholar assistant, you may need to use your knowledge of the texts to provide additional information or insights about Narsil.\n",
      "Also note that the names mentioned in this conversation are from J.R.R. Tolkien's Middle-earth legendarium.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "for chunk in qa_chain.stream({\"input\": query, \"query\": query}):\n",
    "    if \"answer\" in chunk:\n",
    "        print(chunk[\"answer\"], end=\"\", flush=True)\n",
    "\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
